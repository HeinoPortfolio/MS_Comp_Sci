{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb007a7",
   "metadata": {},
   "source": [
    "# Module 11 Text Processing\n",
    "\n",
    "**Topics**:\n",
    "- Text Processing\n",
    "- Tokenizing strings\n",
    "- Use of the NLTK toolkit\n",
    "- Loading and using stopwords\n",
    "- Stemming words\n",
    "- Lemmatizing words\n",
    "\n",
    "**Notes**:\n",
    "- Detecting space, new line, and tab are common in processing text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a9cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4e26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "abcdefghijklmnopqrstuvwxyz\n",
      "0123456789\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      " \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# Useful string constants \n",
    "print(string.ascii_letters)\n",
    "print(string.ascii_uppercase)\n",
    "print(string.ascii_lowercase)\n",
    "print(string.digits)\n",
    "print(string.punctuation)\n",
    "print(string.whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a32835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first character is space, \n",
    "string.whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c30db0",
   "metadata": {},
   "source": [
    "### Demo of useful String functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38018902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "TEST\n"
     ]
    }
   ],
   "source": [
    "s = 'Test'\n",
    "\n",
    "print(s.lower())\n",
    "\n",
    "print(s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0975b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test me.\n"
     ]
    }
   ],
   "source": [
    "s= 'test me.'\n",
    "\n",
    "print(s.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec20a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Me Again\n"
     ]
    }
   ],
   "source": [
    "s ='test me again'\n",
    "\n",
    "print(s.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8437b949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "s ='test'\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6105c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8f7c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= '321'\n",
    "\n",
    "t.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a6c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t='?'\n",
    "\n",
    "t.isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285cbbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'test123'\n",
    "\n",
    "s.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62e6b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'test123'\n",
    "\n",
    "s.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b31bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Test'\n",
    "\n",
    "s.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20630bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s ='T'\n",
    "\n",
    "s.isspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd804979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='\\n'\n",
    "\n",
    "s.isspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc681c",
   "metadata": {},
   "source": [
    "### Tokenize string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cf334ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7942402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"Hello there! It is nice to see you again. Do you have any questions?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "331fe6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tekenize the string\n",
    "\n",
    "sentences = sent_tokenize(para)\n",
    "\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6261a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there!\n",
      "['Hello there!', 'It is nice to see you again.', 'Do you have any questions?']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a1889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is nice to see you again.\n",
      "['It', 'is', 'nice', 'to', 'see', 'you', 'again', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the first sentence\n",
    "print(sentences[1])\n",
    "\n",
    "print(word_tokenize(sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09a00c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'is', 'nice', 'to', 'see', 'you', 'again', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(sentences[1])\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd9e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7950d",
   "metadata": {},
   "source": [
    "### Remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd5eb5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is nice to see you again'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1].translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21d68871",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = sentences[1].translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "350de964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the sentence\n",
    "\n",
    "words = word_tokenize(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f19146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# to check to make sure they are all words\n",
    "for w in words:\n",
    "    print(w.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e3468ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'nice', 'to', 'see', 'you', 'again']\n"
     ]
    }
   ],
   "source": [
    "# Save the tokenized words to a list\n",
    "\n",
    "words_saved =[]\n",
    "\n",
    "for w in words:\n",
    "    if (w.isalpha() == True):\n",
    "        words_saved.append(w.lower())\n",
    "        \n",
    "print(words_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a1069",
   "metadata": {},
   "source": [
    "### Loading the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ebc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46c1bbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stop_words = stopwords.words('English')\n",
    "\n",
    "len(english_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "835c2b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 20 stopwords\n",
    "english_stop_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22ccc4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "is\n",
      "to\n",
      "you\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "# View how many stop words are in the list of tokenized words\n",
    "\n",
    "for w in words_saved:\n",
    "   \n",
    "    if w in english_stop_words :\n",
    "        print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83e8c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'see']\n"
     ]
    }
   ],
   "source": [
    "# Make a list of words that are not found in stopwords\n",
    "\n",
    "words_saved_2 = []\n",
    "\n",
    "for w in words_saved:\n",
    "   \n",
    "    if w not in english_stop_words :\n",
    "        words_saved_2.append(w)\n",
    "\n",
    "print(words_saved_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b624a",
   "metadata": {},
   "source": [
    "### Stemming Words Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20924dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['kick','kicks','kicked','kicking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf925b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NLTK Porter Stemmer\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8da8e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kick\n",
      "kick\n",
      "kick\n",
      "kick\n"
     ]
    }
   ],
   "source": [
    "for w in tokens:\n",
    "    print(porter.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65838bc",
   "metadata": {},
   "source": [
    "### Lemmatizing Words Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b25d9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d30495b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kick\n",
      "kick\n",
      "kicked\n",
      "kicking\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the list\n",
    "\n",
    "for w in tokens:\n",
    "    print(wnl.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "314d2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'It is nice to see you again.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86fbcaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsu_text = []\n",
    "\n",
    "in_file = open('bsu_text_1.txt')\n",
    "\n",
    "for line in in_file:\n",
    "    bsu_text.append(line)\n",
    "    \n",
    "in_file.close()\n",
    "\n",
    "len(bsu_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb2cf6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ball State University has partnered with Coursera, one of the largest online learning platforms in the world, to bring you the online master of science in data science. \\n', 'The curriculum is designed by Ball State University, courses are taught by our accomplished faculty, and content is delivered through the Coursera platform.']\n"
     ]
    }
   ],
   "source": [
    "print(bsu_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
